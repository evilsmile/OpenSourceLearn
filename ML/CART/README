线性回归创建的模型需要拟合所有的样本点（除了局部加权线性回归）。当数据拥有众多
特征并且特征之间关系十分复杂时，构建全局模型的想法就比较困难。而且生活中很多
问题是非线性的，无法用全局线性模型来拟合所有的数据。一种方法是将数据集递归地
切分成很多份易建模的数据，并对可以拟合的小数据集用线性回归建模。

在Chapter03中介绍了贪心算法的决策树，构建算法是ID3，每次选取当前最佳特征来分割
数据，并且按照这个特征的所有可能取值来划分，一旦切分完成，这个特征在之后的执行
过程中不会再有任何用处。这种方法切分过于迅速，并且需要将连续型数据离散化后才能
处理，这样就破坏了连续变量的内存性质。

二元切分法是另一种树构建算法，每次将数据集切分两半，如果数据的某个特征满足这个
切分的条件，就将这些数据放入左子树，否则右子树。二元切分法也节省了树的构建时间，
但树一般都是离线构建，因此意义不大。CART，Classification And Regression Tree，
分类回归树，使用二元切分来处理连续型变量，并用R^2取代香家熵来分析模型的效果。

数据集中会包含一些复杂的相互关系，使输入数据和目标变量之间存在非线性的关系。
对于这种复杂关系的建模，可以采用树模型来对预测进行分段，包括分段常数（回归树）
和分段直线（模型树）。
回归分类树CART算法用于构建二元树对离散/连续弄数据进行切分。根据使用的不同误差
准则方法，可以通过CART算法构建模型树和回归树。但是该算法构建的树倾向于过拟合，
可采用剪枝的方法解决。剪枝方法分为预剪枝（在树的构建过程中人工设置参数防止过
拟合）和后剪枝（构建完毕进行删除/合并分支）。
Tkinter是python的一个最常用的GUI工具包，结合matplotlib可以构建更强大的GUI。
